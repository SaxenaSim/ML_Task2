# ML_Task2

## EDA, Pre-processing, and Random Forest Algorithm Implementation using PySpark

This repository contains a Jupyter Notebook implementing Exploratory Data Analysis (EDA), pre-processing, and a Random Forest algorithm using PySpark on a dataset.

## Dataset

The dataset used for this analysis is available in the file [dataset.csv](https://gist.githubusercontent.com/curran/a08a1080b88344b0c8a7/raw/0e7a9b0a5d22642a06d3d5b9bcbad9890c8ee534/iris.csv).

## Notebook

The notebook [random-forest.ipynb](https://github.com/SaxenaSim/ML_Task2/blob/main/random_forest.ipynb) includes the following sections:

1. **Exploratory Data Analysis (EDA)**: Visualizing and understanding the dataset using PySpark.
2. **Pre-processing**: Cleaning the data, handling missing values, encoding categorical variables, and preparing features for model training.
3. **Random Forest Algorithm**: Implementing a Random Forest classifier using PySpark and evaluating its performance.

## Dependencies

To run the notebook, you need to have the following dependencies installed:

- [Apache Spark](https://spark.apache.org/)
- [PySpark](https://spark.apache.org/docs/latest/api/python/index.html)
- [Jupyter Notebook](https://jupyter.org/)

## Usage

1. Clone this repository:
   ```bash
   git clone https://github.com/SaxenaSim/ML_Task2.git
   ```

2. Navigate to the cloned directory:
   ```bash
   cd repositoryname
   ```
3. Open and run the Jupyter Notebook:
   ```bash
   jupyter notebook Notebook.ipynb
   ```
4. Follow the instructions in the notebook to execute each cell and observe the results.
   

